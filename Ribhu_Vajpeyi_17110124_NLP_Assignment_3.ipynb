{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ribhu_Vajpeyi_17110124_NLP_Assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RadoxWoolf/Ribhu_Vajpeyi_17110124_NLP_Assignment_3/blob/master/Ribhu_Vajpeyi_17110124_NLP_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmItylUYWkkB",
        "colab_type": "code",
        "outputId": "f503d4e7-878f-428e-e3de-d984650a5fa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive',  force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWojR16FW9Ua",
        "colab_type": "text"
      },
      "source": [
        "#Preprocessing Train and Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA38pQF97UGx",
        "colab_type": "text"
      },
      "source": [
        "**Training Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCpdNJpdqGOu",
        "colab_type": "code",
        "outputId": "f33f5650-e55b-4585-e0ae-3f88b58745f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "f = open(\"/content/gdrive/Shared drives/NLP/Assignment 3/train.txt\", 'r')\n",
        "train_tweets_raw_lst=[]\n",
        "num_tweets=0\n",
        "while(num_tweets!=15131):\n",
        "  lst=[]\n",
        "  num_tweets=num_tweets+1\n",
        "  for tweet in f:\n",
        "    tweet = tweet.strip()\n",
        "    if len(tweet.split())>1:\n",
        "      lst.append(tweet.split())\n",
        "    if tweet=='':\n",
        "      train_tweets_raw_lst.append(lst)\n",
        "      break\n",
        "\n",
        "train_tweets_raw_lst[5]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['meta', '68', 'negative'],\n",
              " ['@', 'O'],\n",
              " ['noirnaveed', 'Eng'],\n",
              " ['@', 'O'],\n",
              " ['AngelAhana6', 'Eng'],\n",
              " ['@', 'O'],\n",
              " ['cricketworldcup', 'Eng'],\n",
              " ['Bhosdike', 'Eng'],\n",
              " ['tum', 'Hin'],\n",
              " ['pechvade', 'Hin'],\n",
              " ['ki', 'Hin'],\n",
              " ['tatti', 'Hin'],\n",
              " ['hi', 'Hin'],\n",
              " ['rahoge', 'Hin'],\n",
              " ['bc', 'Hin']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAKrLUdC_Q2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tweets_stance = []\n",
        "train_tweets_id = []\n",
        "for tweet in train_tweets_raw_lst:\n",
        "  train_tweets_id.append(tweet[0][1])\n",
        "  train_tweets_stance.append(tweet[0][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLR3Tqf_otc5",
        "colab_type": "code",
        "outputId": "c0a50e2e-28c3-4b61-9bd7-72759d3c588d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "train_tweets_stance_count = Counter(train_tweets_stance)\n",
        "train_tweets_stance_count"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 4459, 'neutral': 5638, 'positive': 5034})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb1bylRj_l3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train_tweets_stance.txt\",'w') as f:\n",
        "  for ID, stance in zip(train_tweets_id, train_tweets_stance):\n",
        "      f.write(ID+\"\\t\"+stance+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHMQFi15Zj6z",
        "colab_type": "code",
        "outputId": "0248e9bc-83ec-446e-c1b4-fba72724c9aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open(\"train_tweets_stance.txt\", 'r')\n",
        "train_tweets_stance=[]\n",
        "for tweet in f:\n",
        "  tweet = tweet.strip()\n",
        "  if len(tweet.split(\"\\t\"))>1:\n",
        "    train_tweets_stance.append(tweet.split(\"\\t\")[-1])\n",
        "\n",
        "len(train_tweets_stance)\n",
        "#train_tweets_stance[10]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpTVvdNkPDOZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stance_onehot = {'negative':0, \"neutral\":1,\"positive\":2}\n",
        "train_tweets_stance_onehot = []\n",
        "for stance in train_tweets_stance:\n",
        "  train_tweets_stance_onehot.append(stance_onehot[stance])\n",
        "\n",
        "import numpy as np \n",
        "train_tweets_stance_onehot = np.array(train_tweets_stance_onehot)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehot_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "onehot_enc.fit(train_tweets_stance_onehot.reshape(-1, 1))\n",
        "train_tweets_stance_onehot = onehot_enc.transform(train_tweets_stance_onehot.reshape(-1, 1)).toarray()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAzkOJpfaGU2",
        "colab_type": "code",
        "outputId": "168a552c-af8b-440e-8c5d-ab4909268c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "train_tweets_stance_onehot"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0q24AfHyBtm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "train_tweets_cleaned = []\n",
        "for i in range(15131):\n",
        "  temp = []\n",
        "  for j in range(len(train_tweets_raw_lst[i])):\n",
        "    if bool(re.match(\"^[a-zA-Z]+$\",train_tweets_raw_lst[i][j][0])):\n",
        "      if bool(re.match(\"^(http)|(^t$)|(^co$)\",train_tweets_raw_lst[i][j][0])):\n",
        "        continue\n",
        "      else:\n",
        "        train_tweets_raw_lst[i][j][0] = train_tweets_raw_lst[i][j][0].lower()\n",
        "        temp.append(train_tweets_raw_lst[i][j])\n",
        "  train_tweets_cleaned.append(temp[1:])\n",
        "\n",
        "#train_tweets_cleaned[0]\n",
        "#len(train_tweets_cleaned[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXs0ztKPvoPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"train_tweets.txt\",'w') as f:\n",
        "  for ID, tweet in zip(train_tweets_id, train_tweets_cleaned):\n",
        "      f.write(ID+\"\\t\"+\" \".join([j[0] for j in tweet[1:-1]])+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RZs5IuKZkIg",
        "colab_type": "code",
        "outputId": "0d7dc9d5-ee3b-43f3-96a9-bf8f85e03042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open(\"train_tweets.txt\", 'r')\n",
        "train_tweets=[]\n",
        "for tweet in f:\n",
        "  tweet = tweet.strip()\n",
        "  if len(tweet.split(\"\\t\"))>1:\n",
        "    train_tweets.append(tweet.split(\"\\t\")[-1])\n",
        "  elif tweet.split(\"\\t\")[0] == '18288':\n",
        "    train_tweets.append(\"tweet\")\n",
        "    #ids.append(tweet.split(\"\\t\")[0])\n",
        "  elif tweet.split(\"\\t\")[0] == '35253':\n",
        "    train_tweets.append(\"JCB dekho\")\n",
        "    #ids.append(tweet.split(\"\\t\")[0])\n",
        "  \n",
        "len(train_tweets)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "c_Ud6djIXTrz"
      },
      "source": [
        "**Testing Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m967npXv57ku",
        "colab_type": "code",
        "outputId": "49af2126-8249-4b0f-e82b-280e16f7f8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "f = open(\"/content/gdrive/Shared drives/NLP/Assignment 3/test.txt\", 'r')\n",
        "test_tweets_raw_lst=[]\n",
        "num_tweets=0\n",
        "while(num_tweets!=1869):\n",
        "  lst=[]\n",
        "  num_tweets=num_tweets+1\n",
        "  for tweet in f:\n",
        "    tweet = tweet.strip()\n",
        "    if len(tweet.split())>1:\n",
        "      lst.append(tweet.split())\n",
        "    if tweet=='':\n",
        "      test_tweets_raw_lst.append(lst)\n",
        "      break\n",
        "\n",
        "test_tweets_raw_lst[5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['meta', '26', 'positive'],\n",
              " ['@', 'O'],\n",
              " ['imVkohli', 'Eng'],\n",
              " ['Best', 'Eng'],\n",
              " ['of', 'Eng'],\n",
              " ['luck', 'Eng'],\n",
              " ['@', 'O'],\n",
              " ['imVkohli', 'Hin'],\n",
              " ['sir', 'Hin'],\n",
              " ['World', 'Eng'],\n",
              " ['Cup', 'Hin'],\n",
              " ['ke', 'Hin'],\n",
              " ['liye', 'Hin'],\n",
              " ['bhot', 'Hin'],\n",
              " ['bhot', 'Hin'],\n",
              " ['subhkamnaye', 'Hin']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVHc7aXq6Gdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_tweets_stance = []\n",
        "test_tweets_id = []\n",
        "for tweet in test_tweets_raw_lst:\n",
        "  test_tweets_id.append(tweet[0][1])\n",
        "  test_tweets_stance.append(tweet[0][2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE8HEd7gXQBX",
        "colab_type": "code",
        "outputId": "c1d133f8-67a1-4df2-b7ef-6b85d0ac987f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "test_tweets_stance_count = Counter(test_tweets_stance)\n",
        "test_tweets_stance_count"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'negative': 533, 'neutral': 754, 'positive': 582})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDIMDfdhXaL2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"test_tweets_stance.txt\",'w') as f:\n",
        "  for ID, stance in zip(test_tweets_id, test_tweets_stance):\n",
        "      f.write(ID+\"\\t\"+stance+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzQPC-ewh2MU",
        "colab_type": "code",
        "outputId": "bda41bbd-d097-447b-b7ba-f4c172184040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open(\"test_tweets_stance.txt\", 'r')\n",
        "test_tweets_stance=[]\n",
        "for tweet in f:\n",
        "  tweet = tweet.strip()\n",
        "  if len(tweet.split(\"\\t\"))>1:\n",
        "    test_tweets_stance.append(tweet.split(\"\\t\")[-1])\n",
        "\n",
        "len(test_tweets_stance)\n",
        "#test_tweets_stance[10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvDJS6qkZ4ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stance_onehot = {'negative':0, \"neutral\":1,\"positive\":2}\n",
        "\n",
        "test_tweets_stance_onehot = []\n",
        "for stance in test_tweets_stance:\n",
        "  test_tweets_stance_onehot.append(stance_onehot[stance])\n",
        "\n",
        "import numpy as np \n",
        "test_tweets_stance_onehot = np.array(test_tweets_stance_onehot)\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "onehot_enc = OneHotEncoder(handle_unknown='ignore')\n",
        "onehot_enc.fit(test_tweets_stance_onehot.reshape(-1, 1))\n",
        "test_tweets_stance_onehot = onehot_enc.transform(test_tweets_stance_onehot.reshape(-1, 1)).toarray()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LalbiyQpuHkZ",
        "colab_type": "code",
        "outputId": "2499ce1f-354a-408d-d6e1-d969056c5a79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "test_tweets_stance_onehot"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIW8VS_eapvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "test_tweets_cleaned = []\n",
        "for i in range(1869):\n",
        "  temp = []\n",
        "  for j in range(len(test_tweets_raw_lst[i])):\n",
        "    if bool(re.match(\"^[a-zA-Z]+$\",test_tweets_raw_lst[i][j][0])):\n",
        "      if bool(re.match(\"^(http)|(^t$)|(^co$)\",test_tweets_raw_lst[i][j][0])):\n",
        "        continue\n",
        "      else:\n",
        "        test_tweets_raw_lst[i][j][0] = test_tweets_raw_lst[i][j][0].lower()\n",
        "        temp.append(test_tweets_raw_lst[i][j])\n",
        "  test_tweets_cleaned.append(temp[1:])\n",
        "\n",
        "#test_tweets_cleaned[0]\n",
        "#len(test_tweets_cleaned[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T96-y6X9nOqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"test_tweets.txt\",'w') as f:\n",
        "  for ID, tweet in zip(test_tweets_id, test_tweets_cleaned):\n",
        "      f.write(ID+\"\\t\"+\" \".join([j[0] for j in tweet[1:-1]])+\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lgs4ObEZkAw",
        "colab_type": "code",
        "outputId": "0057ff3b-cc45-4c42-a0eb-7331a9449510",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f = open(\"test_tweets.txt\", 'r')\n",
        "test_tweets=[]\n",
        "for tweet in f:\n",
        "  tweet = tweet.strip()\n",
        "  if len(tweet.split(\"\\t\"))>1:\n",
        "    test_tweets.append(tweet.split(\"\\t\")[-1])\n",
        "\n",
        "len(test_tweets)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EtXl7b07OO5",
        "colab_type": "text"
      },
      "source": [
        "#Embeddings for Training and Test Data (Translation and Transliteration Done Seperately)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1kAN3yIESQ5",
        "colab_type": "code",
        "outputId": "31d0dccf-f957-4031-b9bd-df2997763887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.4)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2+cu100)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.7)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.9.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.7)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.5)\n",
            "Requirement already satisfied: tiny-tokenizer[all] in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.11.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1+cu100)\n",
            "Requirement already satisfied: ipython==7.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (7.6.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: transformers>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (2.1.1)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (1.17.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (4.3.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: sentencepiece; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.1.83)\n",
            "Requirement already satisfied: natto-py; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.9.0)\n",
            "Requirement already satisfied: kytea; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.1.4)\n",
            "Requirement already satisfied: SudachiPy; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.3)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (41.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.0.10)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.14)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (0.0.35)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->flair) (0.46)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (1.13.2)\n",
            "Requirement already satisfied: dartsclone~=0.6.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.6)\n",
            "Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->flair) (0.14.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
            "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2019.9.11)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.14 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (2.19)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.29.14)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.14->boto3->transformers>=2.0.0->flair) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2BbHNQwoXnw4"
      },
      "source": [
        "**Embeddings for Training Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ep1eE6-G762",
        "colab_type": "code",
        "outputId": "b407d103-0987-448d-c976-0b29db0e168f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "f = open(\"/content/gdrive/Shared drives/NLP/train_tweets_translated.txt\", \"r\")\n",
        "\n",
        "tweets = []\n",
        "for tweet in f:\n",
        "  if tweet != \"\\n\":\n",
        "    tweets.append(tweet[:-1])\n",
        "\n",
        "raw = []\n",
        "csnli = []\n",
        "english = []\n",
        "\n",
        "i = 0\n",
        "while i < len(tweets)-2:\n",
        "  raw.append(tweets[i])\n",
        "  csnli.append(tweets[i+1])\n",
        "  english.append(tweets[i+2])\n",
        "  i+=3\n",
        "\n",
        "\n",
        "train_tweets_sent = []\n",
        "for tweet in english:\n",
        "  sent = Sentence(tweet)\n",
        "  train_tweets_sent.append(sent)\n",
        "\n",
        "\n",
        "len(train_tweets_sent)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15131"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOyvIhvOTwTf",
        "colab_type": "code",
        "outputId": "9493be5b-287c-4499-d4d5-2cda78604daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_tweets_sent[5]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence: \"you will remain a crutch of crick soaked\" - 8 Tokens"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBTe6l_1G83D",
        "colab_type": "code",
        "outputId": "20fc0f4d-8a99-4ecf-ad46-b855c9e6cc7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from flair.embeddings import BertEmbeddings\n",
        "BERT_embeddings = BertEmbeddings(\"bert-base-cased\")\n",
        "\n",
        "train_tweets_embeddings = []\n",
        "for sent in train_tweets_sent:\n",
        "  train_tweets_embeddings.append(BERT_embeddings.embed(sent))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "BERT_train_tweets_embeddings = []\n",
        "for i in train_tweets_embeddings:\n",
        "  temp = []\n",
        "  for j in i[0]:\n",
        "    temp.append(np.array(j.embedding.cpu()))\n",
        "  BERT_train_tweets_embeddings.append(np.array(temp))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 213450/213450 [00:00<00:00, 2464860.18B/s]\n",
            "100%|██████████| 313/313 [00:00<00:00, 146781.88B/s]\n",
            "100%|██████████| 435779157/435779157 [00:06<00:00, 69528127.96B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqO-V9yKXvxN"
      },
      "source": [
        "**Embeddings for Testinging Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UdB00EIb2Hv",
        "colab_type": "code",
        "outputId": "cc7f85cf-5c18-4672-9990-3c254c7f0660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from flair.data import Sentence\n",
        "\n",
        "f = open(\"/content/gdrive/Shared drives/NLP/test_tweets_translated.txt\", \"r\")\n",
        "\n",
        "tweets = []\n",
        "for tweet in f:\n",
        "  if tweet != \"\\n\":\n",
        "    tweets.append(tweet[:-1])\n",
        "\n",
        "raw = []\n",
        "csnli = []\n",
        "english = []\n",
        "\n",
        "i = 0\n",
        "while i < len(tweets)-2:\n",
        "  raw.append(tweets[i])\n",
        "  csnli.append(tweets[i+1])\n",
        "  english.append(tweets[i+2])\n",
        "  i+=3\n",
        "\n",
        "test_tweets_sent = []\n",
        "for tweet in english:\n",
        "  sent = Sentence(tweet)\n",
        "  test_tweets_sent.append(sent)\n",
        "\n",
        "\n",
        "len(test_tweets_sent)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1869"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6IrrpmqWVCB",
        "colab_type": "code",
        "outputId": "2cf88a4d-bfb2-4abc-bea0-cf6a50424aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_tweets_sent[5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence: \"ghost of best for luck imvkohli sir world cup\" - 9 Tokens"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwMv866QcE4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.embeddings import BertEmbeddings\n",
        "BERT_embeddings = BertEmbeddings(\"bert-base-cased\")\n",
        "\n",
        "test_tweets_embeddings = []\n",
        "for sent in test_tweets_sent:\n",
        "  test_tweets_embeddings.append(BERT_embeddings.embed(sent))\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "BERT_test_tweets_embeddings = []\n",
        "for i in test_tweets_embeddings:\n",
        "  temp = []\n",
        "  for j in i[0]:\n",
        "    temp.append(np.array(j.embedding.cpu()))\n",
        "  BERT_test_tweets_embeddings.append(np.array(temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z5mdPMn7q-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#np.save(\"BERT_test_tweets_embeddings.npy\", BERT_test_tweets_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1athAGyMLUTU",
        "colab_type": "code",
        "outputId": "59b94894-34a8-4cba-9bc5-a166ba507b43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(BERT_train_tweets_embeddings[2].shape,BERT_test_tweets_embeddings[2].shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14, 3072) (10, 3072)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfJMF3aVAYnF",
        "colab_type": "text"
      },
      "source": [
        "#Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBoB2mBiRfZQ",
        "colab_type": "code",
        "outputId": "42bfb451-631f-4179-ba1a-54bb6ebff6f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "!pip install keras_Self_attention\n",
        "!pip install keras_multi_head\n",
        "!pip install keras_tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras_Self_attention in /usr/local/lib/python3.6/dist-packages (0.41.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_Self_attention) (1.17.4)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_Self_attention) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.3.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_Self_attention) (1.0.8)\n",
            "Requirement already satisfied: keras_multi_head in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras_multi_head) (1.17.4)\n",
            "Requirement already satisfied: keras-self-attention==0.41.0 in /usr/local/lib/python3.6/dist-packages (from keras_multi_head) (0.41.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_multi_head) (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_multi_head) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_multi_head) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_multi_head) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_multi_head) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_multi_head) (1.3.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_multi_head) (1.1.0)\n",
            "Requirement already satisfied: keras_tqdm in /usr/local/lib/python3.6/dist-packages (2.0.1)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (2.2.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras_tqdm) (4.28.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.17.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.3.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras_tqdm) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c_EWaZ3RXIV",
        "colab_type": "code",
        "outputId": "0d1199ac-210f-4fd4-c3b7-92bb1791797f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "import pickle\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.nn.utils.rnn import PackedSequence, pack_padded_sequence, pad_sequence\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import GRU\n",
        "from keras.layers import Bidirectional\n",
        "from keras import regularizers\n",
        "from keras import optimizers\n",
        "from keras.layers import merge, Multiply\n",
        "from keras.layers.core import *\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import *\n",
        "from keras.layers import concatenate\n",
        "import keras\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.layers import Dropout\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from keras_multi_head import MultiHead\n",
        "from keras_multi_head import MultiHeadAttention\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras import regularizers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFkZQFUQu32O",
        "colab_type": "code",
        "outputId": "da41fdf9-ec64-494d-c118-296b03de362f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "train_tweets_max_len = max([len(tweet) for tweet in train_tweets_cleaned])\n",
        "test_tweets_max_len = max([len(tweet) for tweet in test_tweets_cleaned])\n",
        "\n",
        "print(train_tweets_max_len,test_tweets_max_len)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4b8f95956e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_tweets_max_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_tweets_cleaned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_tweets_max_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_tweets_cleaned\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_tweets_max_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_tweets_max_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_tweets_cleaned' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2bM0pV5NoHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tweets = BERT_train_tweets_embeddings\n",
        "test_tweets = BERT_test_tweets_embeddings\n",
        "train_tweet_embed_list = []\n",
        "for i in train_tweets:\n",
        "  train_tweet_embed_list.append(torch.tensor(i[:28]).cuda())\n",
        "train_tweets = pad_sequence(train_tweet_embed_list, batch_first=True)\n",
        "\n",
        "test_tweet_embed_list = []\n",
        "for i in test_tweets:\n",
        "  test_tweet_embed_list.append(torch.tensor(i[:28]).cuda())\n",
        "test_tweets = pad_sequence(test_tweet_embed_list, batch_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H7WgvMJf12K",
        "colab_type": "code",
        "outputId": "ae1af423-e33f-4465-8561-c2fde0be6c98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#np.array([test_tweets[0].cpu().numpy()]).shape\n",
        "test_tweets.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1869, 28, 3072])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlUqTCuAX4En",
        "colab_type": "text"
      },
      "source": [
        "**Bi-LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoRAcn_pRAqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_Bi_LSTM = Sequential()\n",
        "model_Bi_LSTM.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(28, 3072), merge_mode='concat'))\n",
        "model_Bi_LSTM.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "model_Bi_LSTM.add(Dense(5, activation='softmax'))\n",
        "model_Bi_LSTM.add(Dense(3, activation='softmax'))\n",
        "model_Bi_LSTM.summary()\n",
        "model_Bi_LSTM.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_Bi_LSTM.fit(x=train_tweets.cpu().numpy(), y=train_tweets_stance_onehot, validation_data=(test_tweets.cpu().numpy(), test_tweets_stance_onehot),\tbatch_size=28, epochs=10, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAVR8x6uVX9w",
        "colab_type": "code",
        "outputId": "6a3c9188-e0e0-4bbb-c236-38592fa631d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model_Bi_LSTM.evaluate(test_tweets.cpu().numpy(), test_tweets_stance_onehot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 7s 4ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9912501937441165, 0.5077581596030086]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MWoNzl_5kTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stance_prediction = []\n",
        "\n",
        "for arr in test_tweets.cpu().numpy():\n",
        "  stance_prediction.append(model_Bi_LSTM.predict_classes(np.array([arr])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3gn8PW65oSY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stance_onehot = {'negative':0,'neutral':1,'positive':2}\n",
        "\n",
        "for i, sent in enumerate(test_tweets_stance):\n",
        "  test_tweets_stance[i] = stance_onehot[sent]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmCOXXvr5sLy",
        "colab_type": "code",
        "outputId": "8f0afc07-6812-4c48-f406-ca040ad1009b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "stance_choices=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(test_tweets_stance, stance_prediction), columns=stance_choices, index=stance_choices)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(test_tweets_stance, stance_prediction))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(test_tweets_stance, stance_prediction, stance_choices=stance_choices))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        420       76        37\n",
            "neutral         368      222       164\n",
            "positive        152      123       307\n",
            "\n",
            "\n",
            "Accuracy:  0.5077581594435527\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.45      0.79      0.57       533\n",
            "     neutral       0.53      0.29      0.38       754\n",
            "    positive       0.60      0.53      0.56       582\n",
            "\n",
            "    accuracy                           0.51      1869\n",
            "   macro avg       0.53      0.54      0.50      1869\n",
            "weighted avg       0.53      0.51      0.49      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faefZS0uYHF4",
        "colab_type": "text"
      },
      "source": [
        "**Bi-LSTM + Self Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD253wDNR6Gm",
        "colab_type": "code",
        "outputId": "0927c3a1-b026-4ae2-cb77-e0a6ce49273e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "\"\"\"\n",
        "#### Self Attention Library, no appends\n",
        "**MODEL 1.1 SelfAtt**\n",
        "\"\"\"\n",
        "\n",
        "model_Bi_LSTM_self_atten = Sequential()\n",
        "model_Bi_LSTM_self_atten.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(31, 3072), merge_mode='concat'))\n",
        "model_Bi_LSTM_self_atten.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model_Bi_LSTM_self_atten.add(Bidirectional(LSTM(5, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "#model_Bi_LSTM_self_atten.add(Dense(5, activation='softmax'))\n",
        "model_Bi_LSTM_self_atten.add(Dense(3, activation='softmax'))\n",
        "model_Bi_LSTM_self_atten.summary()\n",
        "model_Bi_LSTM_self_atten.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_Bi_LSTM_self_atten.fit(x=train_tweets.cpu().numpy(), y=train_tweets_stance_onehot, validation_data=(test_tweets.cpu().numpy(), test_tweets_stance_onehot),\tbatch_size=64, epochs=15, shuffle=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bidirectional_5 (Bidirection (None, 31, 20)            246640    \n",
            "_________________________________________________________________\n",
            "seq_self_attention_2 (SeqSel (None, 31, 20)            1345      \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 10)                1040      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 249,058\n",
            "Trainable params: 249,058\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/15\n",
            "15131/15131 [==============================] - 64s 4ms/step - loss: 1.0142 - acc: 0.4686 - val_loss: 1.0005 - val_acc: 0.4880\n",
            "Epoch 2/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.9451 - acc: 0.5184 - val_loss: 1.0104 - val_acc: 0.4901\n",
            "Epoch 3/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.9187 - acc: 0.5363 - val_loss: 0.9895 - val_acc: 0.4981\n",
            "Epoch 4/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8967 - acc: 0.5577 - val_loss: 0.9886 - val_acc: 0.5238\n",
            "Epoch 5/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8836 - acc: 0.5678 - val_loss: 0.9807 - val_acc: 0.5281\n",
            "Epoch 6/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8738 - acc: 0.5764 - val_loss: 0.9706 - val_acc: 0.5457\n",
            "Epoch 7/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8636 - acc: 0.5863 - val_loss: 0.9895 - val_acc: 0.5297\n",
            "Epoch 8/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8522 - acc: 0.5942 - val_loss: 0.9793 - val_acc: 0.5334\n",
            "Epoch 9/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8420 - acc: 0.5974 - val_loss: 0.9850 - val_acc: 0.5415\n",
            "Epoch 10/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8351 - acc: 0.6041 - val_loss: 0.9765 - val_acc: 0.5463\n",
            "Epoch 11/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8301 - acc: 0.6122 - val_loss: 0.9931 - val_acc: 0.5350\n",
            "Epoch 12/15\n",
            "15131/15131 [==============================] - 58s 4ms/step - loss: 0.8169 - acc: 0.6171 - val_loss: 0.9848 - val_acc: 0.5548\n",
            "Epoch 13/15\n",
            "15131/15131 [==============================] - 58s 4ms/step - loss: 0.8087 - acc: 0.6254 - val_loss: 0.9816 - val_acc: 0.5564\n",
            "Epoch 14/15\n",
            "15131/15131 [==============================] - 59s 4ms/step - loss: 0.8024 - acc: 0.6301 - val_loss: 0.9956 - val_acc: 0.5618\n",
            "Epoch 15/15\n",
            "15131/15131 [==============================] - 58s 4ms/step - loss: 0.8001 - acc: 0.6290 - val_loss: 0.9816 - val_acc: 0.5554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f74d3702f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-LPpdqAc-Md",
        "colab_type": "code",
        "outputId": "a9c8340a-250c-44ec-b1d5-e1911c9b7cb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model_Bi_LSTM_self_atten.evaluate(test_tweets.cpu().numpy(), test_tweets_stance_onehot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 6s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9815525145630202, 0.5553772071901651]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCN_GXXL2Yrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stance_prediction = []\n",
        "\n",
        "for arr in test_tweets.cpu().numpy():\n",
        "  stance_prediction.append(model_Bi_LSTM_self_atten.predict_classes(np.array([arr])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzVnRlu12tRF",
        "colab_type": "code",
        "outputId": "cb39999b-4c12-4ec0-8902-3e3d8dbed284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "stance_choices=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(test_tweets_stance, stance_prediction), columns=stance_choices, index=stance_choices)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(test_tweets_stance, stance_prediction))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(test_tweets_stance, stance_prediction, stance_choices=stance_choices))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        337      154        42\n",
            "neutral         219      377       158\n",
            "positive        100      158       324\n",
            "\n",
            "\n",
            "Accuracy:  0.5553772070626003\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.51      0.63      0.57       533\n",
            "     neutral       0.55      0.50      0.52       754\n",
            "    positive       0.62      0.56      0.59       582\n",
            "\n",
            "    accuracy                           0.56      1869\n",
            "   macro avg       0.56      0.56      0.56      1869\n",
            "weighted avg       0.56      0.56      0.55      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncmoVxrSYNkH",
        "colab_type": "text"
      },
      "source": [
        "**GRU + Self Attention**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxZU7oHwVen9",
        "colab_type": "code",
        "outputId": "b8f9c1d1-6d61-4c77-cd75-95f0791e6736",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.layers import GRU\n",
        "model_GRU = Sequential()\n",
        "model_GRU.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5, return_sequences=True), input_shape=(31, 3072), merge_mode='concat'))\n",
        "#model_GRU.add(GRU(8, dropout=0.5, recurrent_dropout=0.5, return_sequences=True))\n",
        "model_GRU.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "model_GRU.add(GRU(8, dropout=0.5, recurrent_dropout=0.5, return_sequences=False))\n",
        "\n",
        "#model_Bi_LSTM.add(Bidirectional(LSTM(10, dropout=0.5, recurrent_dropout=0.5), merge_mode='concat'))\n",
        "#model_GRU.add(Dense(8, activation='softmax'))\n",
        "model_GRU.add(Dense(3, activation='softmax'))\n",
        "model_GRU.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "model_GRU.fit(x=train_tweets.cpu().numpy(), y=train_tweets_stance_onehot, validation_data=(test_tweets.cpu().numpy(), test_tweets_stance_onehot),\tbatch_size=64, epochs=15, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15131 samples, validate on 1869 samples\n",
            "Epoch 1/100\n",
            "15131/15131 [==============================] - 48s 3ms/step - loss: 1.0135 - acc: 0.4635 - val_loss: 0.9947 - val_acc: 0.4831\n",
            "Epoch 2/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.9380 - acc: 0.5273 - val_loss: 0.9704 - val_acc: 0.5254\n",
            "Epoch 3/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.9093 - acc: 0.5491 - val_loss: 0.9772 - val_acc: 0.5292\n",
            "Epoch 4/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8983 - acc: 0.5585 - val_loss: 0.9706 - val_acc: 0.5249\n",
            "Epoch 5/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8839 - acc: 0.5724 - val_loss: 0.9727 - val_acc: 0.5270\n",
            "Epoch 6/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.8739 - acc: 0.5785 - val_loss: 0.9653 - val_acc: 0.5350\n",
            "Epoch 7/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.8679 - acc: 0.5813 - val_loss: 0.9632 - val_acc: 0.5457\n",
            "Epoch 8/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.8586 - acc: 0.5875 - val_loss: 0.9755 - val_acc: 0.5233\n",
            "Epoch 9/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8520 - acc: 0.5942 - val_loss: 0.9680 - val_acc: 0.5324\n",
            "Epoch 10/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8478 - acc: 0.5979 - val_loss: 0.9634 - val_acc: 0.5415\n",
            "Epoch 11/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8411 - acc: 0.6019 - val_loss: 0.9651 - val_acc: 0.5484\n",
            "Epoch 12/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8334 - acc: 0.6142 - val_loss: 0.9721 - val_acc: 0.5538\n",
            "Epoch 13/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8312 - acc: 0.6107 - val_loss: 0.9780 - val_acc: 0.5495\n",
            "Epoch 14/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8217 - acc: 0.6116 - val_loss: 0.9637 - val_acc: 0.5500\n",
            "Epoch 15/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8222 - acc: 0.6148 - val_loss: 0.9679 - val_acc: 0.5548\n",
            "Epoch 16/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8170 - acc: 0.6197 - val_loss: 0.9718 - val_acc: 0.5522\n",
            "Epoch 17/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8142 - acc: 0.6204 - val_loss: 0.9662 - val_acc: 0.5639\n",
            "Epoch 18/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8099 - acc: 0.6217 - val_loss: 0.9694 - val_acc: 0.5618\n",
            "Epoch 19/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8036 - acc: 0.6245 - val_loss: 0.9796 - val_acc: 0.5618\n",
            "Epoch 20/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.8003 - acc: 0.6249 - val_loss: 0.9793 - val_acc: 0.5543\n",
            "Epoch 21/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7943 - acc: 0.6311 - val_loss: 0.9928 - val_acc: 0.5372\n",
            "Epoch 22/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7974 - acc: 0.6291 - val_loss: 0.9914 - val_acc: 0.5522\n",
            "Epoch 23/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7899 - acc: 0.6382 - val_loss: 0.9987 - val_acc: 0.5484\n",
            "Epoch 24/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7895 - acc: 0.6340 - val_loss: 0.9977 - val_acc: 0.5522\n",
            "Epoch 25/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7875 - acc: 0.6319 - val_loss: 1.0038 - val_acc: 0.5452\n",
            "Epoch 26/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7801 - acc: 0.6394 - val_loss: 1.0136 - val_acc: 0.5495\n",
            "Epoch 27/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7827 - acc: 0.6430 - val_loss: 1.0122 - val_acc: 0.5457\n",
            "Epoch 28/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7791 - acc: 0.6411 - val_loss: 0.9969 - val_acc: 0.5532\n",
            "Epoch 29/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7766 - acc: 0.6446 - val_loss: 0.9987 - val_acc: 0.5457\n",
            "Epoch 30/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7744 - acc: 0.6489 - val_loss: 1.0058 - val_acc: 0.5415\n",
            "Epoch 31/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7680 - acc: 0.6465 - val_loss: 1.0028 - val_acc: 0.5597\n",
            "Epoch 32/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7712 - acc: 0.6477 - val_loss: 0.9927 - val_acc: 0.5575\n",
            "Epoch 33/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7685 - acc: 0.6494 - val_loss: 1.0039 - val_acc: 0.5575\n",
            "Epoch 34/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7553 - acc: 0.6527 - val_loss: 1.0126 - val_acc: 0.5575\n",
            "Epoch 35/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7621 - acc: 0.6497 - val_loss: 1.0115 - val_acc: 0.5554\n",
            "Epoch 36/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7589 - acc: 0.6577 - val_loss: 1.0003 - val_acc: 0.5591\n",
            "Epoch 37/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7572 - acc: 0.6565 - val_loss: 1.0040 - val_acc: 0.5511\n",
            "Epoch 38/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7490 - acc: 0.6627 - val_loss: 1.0249 - val_acc: 0.5570\n",
            "Epoch 39/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7550 - acc: 0.6526 - val_loss: 1.0189 - val_acc: 0.5527\n",
            "Epoch 40/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7516 - acc: 0.6581 - val_loss: 1.0216 - val_acc: 0.5436\n",
            "Epoch 41/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7450 - acc: 0.6615 - val_loss: 1.0304 - val_acc: 0.5474\n",
            "Epoch 42/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7451 - acc: 0.6600 - val_loss: 1.0168 - val_acc: 0.5490\n",
            "Epoch 43/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7394 - acc: 0.6670 - val_loss: 1.0261 - val_acc: 0.5629\n",
            "Epoch 44/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7419 - acc: 0.6663 - val_loss: 1.0203 - val_acc: 0.5559\n",
            "Epoch 45/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7410 - acc: 0.6693 - val_loss: 1.0087 - val_acc: 0.5543\n",
            "Epoch 46/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7367 - acc: 0.6690 - val_loss: 1.0324 - val_acc: 0.5548\n",
            "Epoch 47/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7397 - acc: 0.6722 - val_loss: 1.0268 - val_acc: 0.5511\n",
            "Epoch 48/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7386 - acc: 0.6663 - val_loss: 1.0228 - val_acc: 0.5581\n",
            "Epoch 49/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7468 - acc: 0.6614 - val_loss: 1.0119 - val_acc: 0.5554\n",
            "Epoch 50/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7286 - acc: 0.6750 - val_loss: 1.0409 - val_acc: 0.5447\n",
            "Epoch 51/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7283 - acc: 0.6727 - val_loss: 1.0421 - val_acc: 0.5554\n",
            "Epoch 52/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7246 - acc: 0.6769 - val_loss: 1.0457 - val_acc: 0.5532\n",
            "Epoch 53/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7335 - acc: 0.6752 - val_loss: 1.0231 - val_acc: 0.5623\n",
            "Epoch 54/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7258 - acc: 0.6758 - val_loss: 1.0332 - val_acc: 0.5522\n",
            "Epoch 55/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7282 - acc: 0.6735 - val_loss: 1.0476 - val_acc: 0.5436\n",
            "Epoch 56/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7187 - acc: 0.6758 - val_loss: 1.0330 - val_acc: 0.5463\n",
            "Epoch 57/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7153 - acc: 0.6827 - val_loss: 1.0512 - val_acc: 0.5516\n",
            "Epoch 58/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7162 - acc: 0.6805 - val_loss: 1.0438 - val_acc: 0.5618\n",
            "Epoch 59/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7167 - acc: 0.6783 - val_loss: 1.0241 - val_acc: 0.5613\n",
            "Epoch 60/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7145 - acc: 0.6845 - val_loss: 1.0350 - val_acc: 0.5522\n",
            "Epoch 61/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7091 - acc: 0.6857 - val_loss: 1.0439 - val_acc: 0.5575\n",
            "Epoch 62/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7103 - acc: 0.6859 - val_loss: 1.0412 - val_acc: 0.5527\n",
            "Epoch 63/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7143 - acc: 0.6820 - val_loss: 1.0543 - val_acc: 0.5431\n",
            "Epoch 64/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7062 - acc: 0.6834 - val_loss: 1.0549 - val_acc: 0.5548\n",
            "Epoch 65/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7049 - acc: 0.6895 - val_loss: 1.0522 - val_acc: 0.5559\n",
            "Epoch 66/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7001 - acc: 0.6923 - val_loss: 1.0442 - val_acc: 0.5543\n",
            "Epoch 67/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6995 - acc: 0.6930 - val_loss: 1.0485 - val_acc: 0.5548\n",
            "Epoch 68/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.7005 - acc: 0.6902 - val_loss: 1.0808 - val_acc: 0.5409\n",
            "Epoch 69/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6962 - acc: 0.6910 - val_loss: 1.0790 - val_acc: 0.5543\n",
            "Epoch 70/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6969 - acc: 0.6974 - val_loss: 1.0722 - val_acc: 0.5597\n",
            "Epoch 71/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6913 - acc: 0.7003 - val_loss: 1.0815 - val_acc: 0.5495\n",
            "Epoch 72/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6936 - acc: 0.6954 - val_loss: 1.0856 - val_acc: 0.5527\n",
            "Epoch 73/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6916 - acc: 0.6989 - val_loss: 1.0699 - val_acc: 0.5581\n",
            "Epoch 74/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6868 - acc: 0.7007 - val_loss: 1.0881 - val_acc: 0.5506\n",
            "Epoch 75/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6877 - acc: 0.7027 - val_loss: 1.0796 - val_acc: 0.5490\n",
            "Epoch 76/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6841 - acc: 0.7011 - val_loss: 1.0945 - val_acc: 0.5527\n",
            "Epoch 77/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6871 - acc: 0.7009 - val_loss: 1.0846 - val_acc: 0.5463\n",
            "Epoch 78/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6766 - acc: 0.7052 - val_loss: 1.0976 - val_acc: 0.5564\n",
            "Epoch 79/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6795 - acc: 0.7026 - val_loss: 1.1160 - val_acc: 0.5452\n",
            "Epoch 80/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6739 - acc: 0.7058 - val_loss: 1.1072 - val_acc: 0.5527\n",
            "Epoch 81/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6737 - acc: 0.7058 - val_loss: 1.1230 - val_acc: 0.5463\n",
            "Epoch 82/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6860 - acc: 0.6973 - val_loss: 1.0741 - val_acc: 0.5463\n",
            "Epoch 83/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6687 - acc: 0.7126 - val_loss: 1.1118 - val_acc: 0.5522\n",
            "Epoch 84/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6706 - acc: 0.7062 - val_loss: 1.1069 - val_acc: 0.5559\n",
            "Epoch 85/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6761 - acc: 0.7085 - val_loss: 1.0810 - val_acc: 0.5500\n",
            "Epoch 86/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6691 - acc: 0.7105 - val_loss: 1.1152 - val_acc: 0.5532\n",
            "Epoch 87/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6711 - acc: 0.7095 - val_loss: 1.1157 - val_acc: 0.5516\n",
            "Epoch 88/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6665 - acc: 0.7083 - val_loss: 1.0983 - val_acc: 0.5538\n",
            "Epoch 89/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.6679 - acc: 0.7100 - val_loss: 1.1269 - val_acc: 0.5506\n",
            "Epoch 90/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.6671 - acc: 0.7078 - val_loss: 1.1099 - val_acc: 0.5581\n",
            "Epoch 91/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6704 - acc: 0.7093 - val_loss: 1.1014 - val_acc: 0.5447\n",
            "Epoch 92/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6643 - acc: 0.7128 - val_loss: 1.1169 - val_acc: 0.5463\n",
            "Epoch 93/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.6645 - acc: 0.7128 - val_loss: 1.1175 - val_acc: 0.5399\n",
            "Epoch 94/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6626 - acc: 0.7154 - val_loss: 1.0967 - val_acc: 0.5522\n",
            "Epoch 95/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6556 - acc: 0.7128 - val_loss: 1.1143 - val_acc: 0.5457\n",
            "Epoch 96/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6587 - acc: 0.7187 - val_loss: 1.0955 - val_acc: 0.5554\n",
            "Epoch 97/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.6584 - acc: 0.7152 - val_loss: 1.1310 - val_acc: 0.5457\n",
            "Epoch 98/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6597 - acc: 0.7157 - val_loss: 1.1293 - val_acc: 0.5570\n",
            "Epoch 99/100\n",
            "15131/15131 [==============================] - 43s 3ms/step - loss: 0.6506 - acc: 0.7162 - val_loss: 1.1025 - val_acc: 0.5511\n",
            "Epoch 100/100\n",
            "15131/15131 [==============================] - 44s 3ms/step - loss: 0.6607 - acc: 0.7136 - val_loss: 1.1159 - val_acc: 0.5538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f73127a0be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ougPN3w41S9Y",
        "colab_type": "code",
        "outputId": "3dae7eae-4ab2-43b4-87f1-c9798f4475d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model_GRU.evaluate(test_tweets.cpu().numpy(), test_tweets_stance_onehot)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1869/1869 [==============================] - 5s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.1159400339111278, 0.5537720708173504]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW-8s3YYy6ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stance_prediction = []\n",
        "\n",
        "for arr in test_tweets.cpu().numpy():\n",
        "  stance_prediction.append(model_GRU.predict_classes(np.array([arr])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wXDpiz90OzJ",
        "colab_type": "code",
        "outputId": "7aefc61f-7386-47ce-a2a6-e1042c5e64c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "from sklearn.metrics import classification_report as clf\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "\n",
        "stance_choices=['negative','neutral','positive']\n",
        "\n",
        "df_cm = pd.DataFrame(confusion_matrix(test_tweets_stance, stance_prediction), columns=stance_choices, index=stance_choices)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "print(df_cm)\n",
        "print(\"\\n\")\n",
        "print(\"Accuracy: \",accuracy_score(test_tweets_stance, stance_prediction))\n",
        "print(\"\\n\",\"Report:\")\n",
        "print(clf(test_tweets_stance, stance_prediction, stance_choices=stance_choices))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted  negative  neutral  positive\n",
            "Actual                                \n",
            "negative        315      164        54\n",
            "neutral         184      373       197\n",
            "positive         82      153       347\n",
            "\n",
            "\n",
            "Accuracy:  0.5537720706260032\n",
            "\n",
            " Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.54      0.59      0.57       533\n",
            "     neutral       0.54      0.49      0.52       754\n",
            "    positive       0.58      0.60      0.59       582\n",
            "\n",
            "    accuracy                           0.55      1869\n",
            "   macro avg       0.55      0.56      0.56      1869\n",
            "weighted avg       0.55      0.55      0.55      1869\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}